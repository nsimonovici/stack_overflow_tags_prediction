{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_progress_bar(n_tot, n_prog):\n",
    "    from time import sleep\n",
    "    progress = math.ceil((n_prog + 1) * 100 / n_tot)\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(\"[%-100s] %d%%\" %('='*progress, progress))\n",
    "    sys.stdout.flush()\n",
    "    sleep(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(df):\n",
    "    # Looking for missing values\n",
    "    missing_val_df = df.isnull().sum(axis=0).reset_index()\n",
    "    missing_val_df.columns = ['feature', 'missing values']\n",
    "    missing_val_df['missing values (%)'] = 100 - ((df.shape[0] - missing_val_df['missing values']) / df.shape[0] * 100)\n",
    "    missing_val_df = missing_val_df.sort_values('missing values (%)', ascending=False)\n",
    "    missing_val_df\n",
    "    display(missing_val_df)\n",
    "    \n",
    "    return missing_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_tag_synonym(source_tag):\n",
    "    \"\"\"\n",
    "    Short function to replace a tag with its synonyms\n",
    "    \"\"\"\n",
    "    synonyms_dict = dict(zip(tags_synonyms.SourceTagName.values, tags_synonyms.TargetTagName.values))\n",
    "    \n",
    "    if source_tag in synonyms_dict.keys():\n",
    "        replaced_tag = synonyms_dict[source_tag]\n",
    "    else:\n",
    "        replaced_tag = source_tag\n",
    "    return replaced_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tags_minus_nans(row):\n",
    "    row_clean = row.dropna()\n",
    "    joined_row = \"/\".join(row_clean)\n",
    "    return joined_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tags(data):\n",
    "    count_df = pd.Series(data.loc[:, tags_features].squeeze().values.ravel()).value_counts()\n",
    "    ct_df = pd.DataFrame({'Tag': count_df.index,\n",
    "                                  'Count': count_df.values,\n",
    "                                  'Prcentage (%)': (100 * (count_df / count_df.sum())).values})\n",
    "    return ct_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting current path\n",
    "path = os.getcwd()\n",
    "data_files = [file for file in os.listdir(path + '/data') if file.startswith('QueryResults')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop on files and construct main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    data = pd.DataFrame()\n",
    "    print(\"Loading questions full dataset\")\n",
    "    data = pd.read_csv(path + \"/data/data_questions.csv\", sep=',')\n",
    "except :\n",
    "    # Loading first file to get columns names\n",
    "    file = \"QueryResults6.csv\"\n",
    "    try :\n",
    "        data_col_names = pd.read_csv(path + \"/data/\" + file, sep=',')\n",
    "    except FileNotFoundError :\n",
    "        print(\"Please check if the file %s is in the 'data' folder at the current location\" % file)\n",
    "    data_columns = data_col_names.columns\n",
    "    # Save memory\n",
    "    del data_col_names\n",
    "    # Initialise main df\n",
    "    data = pd.DataFrame(columns=data_columns)\n",
    "    # Loop over separate files to build main dataframe\n",
    "    for file in data_files :\n",
    "        print(\"Treating file : %s\" % file)\n",
    "        # Verifying data presence\n",
    "        try :\n",
    "            data_temp = pd.read_csv(path + \"/data/\" + file, sep=',')\n",
    "        except FileNotFoundError :\n",
    "            print(\"Please check if the file %s is in the 'data' folder at the current location\" % file)\n",
    "\n",
    "        # Save data\n",
    "        data = data_raw.append(data_temp)\n",
    "\n",
    "    # Save data\n",
    "    print(\"Saving\")\n",
    "    data.to_csv(\"data/data_questions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    print(\"Loading Tags Synonyms dataset\")\n",
    "    tags_synonyms = pd.read_csv(path + \"/data/Tags_Synonyms.csv\", sep=',')\n",
    "except :\n",
    "    print(\"Please check if the file 'Tags_Synonyms' is in the 'data' folder at the current location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading main dataframe, pre-computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    print(\"Loading clean questions full dataset\")\n",
    "    data = pd.read_csv(path + \"/data/data_questions_clean.csv\", sep=',')\n",
    "    print(\"Clean questions full dataset loaded\")\n",
    "except :\n",
    "    print(\"The 'data_questions_clean.csv' file is not in the 'data' folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only features of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = data.loc[:, ['Body', 'Title', 'Tags']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Duplicates and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of the duplicates\n",
    "print(\"initial shape : \", data_raw.shape)\n",
    "dup = data_raw[data_raw.duplicated()].shape[0]\n",
    "if dup > 0 :\n",
    "    print(\"duplicates found : \", dup)\n",
    "    data_raw = data_raw.drop_duplicates(keep='first')\n",
    "    print(\"Shape without duplicates: \", data_raw.shape)\n",
    "else :\n",
    "    print(\"No duplicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Looking for missing values\n",
    "mv_df = missing_values(data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As *'Tags'* will be our main concern to build a tags prediction tool, we delete those missing Tags values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_features = ['Tag_1', 'Tag_2', 'Tag_3', 'Tag_4', 'Tag_5']\n",
    "interesting_features = ['Body', 'Title', 'clean_body', 'Tags', 'TitleBody', 'clean_title_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_raw = data_raw.dropna(subset=['Tags'])\n",
    "print(\"New shape : \", data_raw.shape)\n",
    "try:\n",
    "    data_raw = data_raw.dropna(subset=['New_Tags_syn'])\n",
    "    print(\"New shape : \", data_raw.shape)\n",
    "except KeyError:\n",
    "    pass\n",
    "try:\n",
    "    data_raw = data_raw.dropna(subset=tags_features, how='all')\n",
    "    print(\"New shape : \", data_raw.shape)\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Body and Title to train our models, delete rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_raw = data_raw.dropna(subset=['Body', 'Title'])\n",
    "print(\"New shape : \", data_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Body and Title may both contains interesting clues, we will concatenate those into one new string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw['TitleBody'] = data_raw.Title + data_raw.Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.loc[:, ['Body', 'Title', 'Tags', 'TitleBody']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Tags chevrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw['New_Tags'] = data_raw.Tags.apply(lambda x: x.strip('<').strip('>').replace('>', '').replace('<', '/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw['n_Tags'] = data_raw.New_Tags.apply(lambda x: len(x.split('/')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating tags in indiviuals features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_lists = data_raw.New_Tags.apply(lambda x: x.split('/')).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise new list of tags\n",
    "filled_tags_list = []\n",
    "# Loop over lists of tags\n",
    "for inner_list in tags_lists:\n",
    "    # Get list length\n",
    "    length = len(inner_list)\n",
    "    # While length not equal to 5 append nans\n",
    "    while length < 5:\n",
    "        inner_list.append(np.nan)\n",
    "        length = len(inner_list)\n",
    "    # Add extended list to new list\n",
    "    filled_tags_list.append(inner_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert lists of tags into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df = pd.DataFrame(filled_tags_list)\n",
    "# Remove empty label\n",
    "tags_df = tags_df.drop(labels=5, axis=1)\n",
    "tags_df.index = data_raw.index\n",
    "tags_df.columns = tags_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add separated tags to dataframe\n",
    "data_raw = pd.concat((data_raw, tags_df), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for tags that can be replaced with synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before removing synonyms :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = [x.split('/') for x in data_raw.New_Tags.values.tolist()]\n",
    "tags_list = [y for x in temp_list for y in x]\n",
    "unique_tags = set(tags_list)\n",
    "print(\"Total of %i unique Tags\" % len(unique_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_syns_in_tags = []\n",
    "for sourcetag in tags_synonyms.SourceTagName:\n",
    "    if sourcetag in unique_tags :\n",
    "        tags_syns_in_tags.append(sourcetag)\n",
    "print(\"%i Tags are synonyms and can be replaced\" % len(tags_syns_in_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace tags that can be replaced (time consuming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag_feature in tags_features :\n",
    "    data_raw.loc[:, tag_feature] = data_raw.loc[:, tag_feature].apply(replace_tag_synonym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save modified raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw['New_Tags_syn'] = data_raw.loc[:, tags_features].apply(join_tags_minus_nans, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing synonyms :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = [x.split('/') for x in data_raw.New_Tags_syn.values.tolist()]\n",
    "tags_list = [y for x in temp_list for y in x]\n",
    "unique_tags_syn = list(set(tags_list))\n",
    "# Remove nan\n",
    "for value in unique_tags_syn:\n",
    "    try:\n",
    "        if np.isnan(value):\n",
    "            unique_tags_syn.remove(value)\n",
    "    except:\n",
    "        pass\n",
    "print(\"Total of %i unique Tags\" % len(unique_tags_syn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.to_csv(\"data/data_questions_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions seem to have one or multiple tags, investigating this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all tags combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tags_comb_counts = data_raw.loc[:, 'New_Tags_syn'].value_counts()\n",
    "print(\"Most popular tag combinations :\")\n",
    "display(tags_comb_counts.head())\n",
    "print(\"Less popular tag combinations :\")\n",
    "display(tags_comb_counts.tail())\n",
    "print(\"Total of %i Tags combinations\" % tags_comb_counts.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "plot = sns.barplot(tags_comb_counts[:10].index.values, tags_comb_counts[:10].values)\n",
    "plot.set_xticklabels(plot.get_xticklabels(), rotation=45, fontsize=12)\n",
    "ax.set_title(\"10 Most popular Tags combinations\", fontsize=12)\n",
    "ax.set_ylabel(\"Count\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many Tags by questions ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.distplot(data_raw.n_Tags, kde=False, bins=10)\n",
    "ax.set_xlabel(\"Number of Tags by question\", fontsize=12)\n",
    "ax.set_ylabel(\"Count\", fontsize=12)\n",
    "ax.set_title(\"Distribution of number of Tags by question\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly 2 and 3 tags over a maximum of 5 are attributed to questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovering and counting all individuals Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting Tags in Dataframe in order to find most popular Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_tags_df = count_tags(data_raw)\n",
    "count_tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular_tag = count_tags_df.Tag[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "plot = sns.barplot(x='Tag', y='Count', data=count_tags_df[:10])\n",
    "plot.set_xticklabels(plot.get_xticklabels(), rotation=45, fontsize=12)\n",
    "ax.set_title(\"10 Most popular Tags\", fontsize=12);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
